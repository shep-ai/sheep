# Task Breakdown (YAML)
# This is the source of truth. Markdown is auto-generated from this file.

name: random-word-file
summary: >
  2 tasks across 2 phases. Phase 1 writes the failing test (RED). Phase 2
  creates RANDOM_WORD.txt so the test passes (GREEN), then reviews for cleanup
  (REFACTOR).

relatedFeatures: []
technologies:
  - Python 3.11+
  - pytest 8.x
relatedLinks: []

tasks:
  - id: task-1
    phaseId: phase-2
    title: 'Write failing test for RANDOM_WORD.txt'
    description: >
      Create tests/test_random_word_file.py with assertions that RANDOM_WORD.txt
      exists at the repo root, contains exactly one whitespace-delimited token,
      and ends with exactly one LF newline. Run pytest to confirm the test fails
      (RED) because the file does not yet exist.
    state: Todo
    dependencies: []
    acceptanceCriteria:
      - 'tests/test_random_word_file.py exists in the tests/ directory'
      - 'The test uses pathlib.Path(__file__).parent.parent to resolve the repo root'
      - 'Three assertions are present: file exists, len(content.split()) == 1, content.endswith("\n")'
      - 'pytest reports the test as FAILED (FileNotFoundError or assertion error) before RANDOM_WORD.txt is created'
      - 'No new imports beyond pathlib and the implicit pytest runner are used'
    tdd:
      red:
        - 'Write tests/test_random_word_file.py with test_random_word_file_exists_and_is_valid()'
        - 'Use repo_root = pathlib.Path(__file__).parent.parent; word_file = repo_root / "RANDOM_WORD.txt"'
        - 'Assert word_file.exists(), assert len(content.split()) == 1, assert content.endswith("\n")'
        - 'Run: pytest tests/test_random_word_file.py — confirm FAILED'
      green:
        - 'No implementation in this task — GREEN is achieved in task-2'
      refactor:
        - 'Verify test function has a clear docstring describing what it checks'
        - 'Confirm no unused imports or dead code in the test module'
    estimatedEffort: '5min'

  - id: task-2
    phaseId: phase-1
    title: 'Create RANDOM_WORD.txt at repo root'
    description: >
      Create RANDOM_WORD.txt at the repository root containing a single lowercase
      English word followed by exactly one LF newline (e.g., "serendipity\n").
      Run pytest to confirm the test from task-1 now passes (GREEN). Review
      file content and test for any cleanup (REFACTOR).
    state: Todo
    dependencies:
      - task-1
    acceptanceCriteria:
      - 'RANDOM_WORD.txt exists at the repository root'
      - 'File contains exactly one lowercase English word — no spaces, tabs, or embedded newlines within the word'
      - 'File ends with exactly one LF newline (POSIX-compliant); no BOM, no CRLF'
      - 'File encoding is UTF-8'
      - 'The word is a recognisable English word (common noun, verb, adjective, or adverb)'
      - 'pytest tests/test_random_word_file.py reports PASSED'
      - 'No changes to pyproject.toml, requirements files, or .gitignore'
    tdd:
      red:
        - 'Confirmed in task-1 — test already fails before this file is created'
      green:
        - 'Create RANDOM_WORD.txt with content "serendipity\n" (or another suitable English word)'
        - 'Run: pytest tests/test_random_word_file.py — confirm PASSED'
        - 'Run: pytest (full suite) — confirm no regressions'
      refactor:
        - 'Verify file has no trailing spaces or extra blank lines (should be exactly word + LF)'
        - 'Optionally run: cat -A RANDOM_WORD.txt to confirm no ^M (CRLF) characters'
        - 'Confirm git status shows RANDOM_WORD.txt as untracked (not in .gitignore)'
    estimatedEffort: '5min'

totalEstimate: '10min'
openQuestions: []

content: |
  ## Summary

  The implementation follows a strict RED-GREEN-REFACTOR TDD cycle across two
  small tasks. The test is written first (task-1) and intentionally fails because
  the file it asserts does not yet exist. RANDOM_WORD.txt is then created
  (task-2), making the test pass. Both tasks end with a refactor review to
  confirm there is no dead code, no extraneous whitespace, and no configuration
  drift. The full pytest suite is run after task-2 to guard against regressions
  in unrelated tests. Total implementation time is roughly 10 minutes.
